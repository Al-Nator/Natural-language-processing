{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9339f749",
   "metadata": {},
   "source": [
    "Лабораторная работа №7: Кластеризация документов и выявление тематик\n",
    "Цель: Создание системы автоматической кластеризации и выделения ключевых тематик в документах.\n",
    "Задания:\n",
    "- Осуществить предварительную обработку текстов (токенизацию, удаление стоп-слов, лемматизацию).Метрика оценки: Качество кластеризации, согласованность кластеров (silhouette coefficient)\n",
    "- Выполнить обучение темы методом LDA или BERTopic и визуализацию результатов.Модели сравнения: k-means clustering, hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd96ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireducks.pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "import spacy\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df64c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/bbc-news-data.csv', sep='\\t')\n",
    "texts = df['content'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87701c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82fef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_nouns(text):\n",
    "    doc = nlp(text)\n",
    "    nouns = [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc\n",
    "        if token.pos_ in (\"NOUN\", \"PROPN\")\n",
    "           and not token.is_stop      \n",
    "           and token.is_alpha     \n",
    "    ]\n",
    "    return \" \".join(nouns)\n",
    "\n",
    "df['clean_text'] = texts.apply(preprocess)\n",
    "df['nouns_only'] = df['clean_text'].apply(preprocess_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "724439b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_purity(true_labels, cluster_labels):\n",
    "    total = 0\n",
    "    for cluster in set(cluster_labels):\n",
    "        idx = (cluster_labels == cluster)\n",
    "        most_common = pd.Series(true_labels[idx]).mode()[0]\n",
    "        total += sum(true_labels[idx] == most_common)\n",
    "    return total / len(cluster_labels)\n",
    "\n",
    "n_clusters = 5\n",
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=5)\n",
    "X = vectorizer.fit_transform(df['nouns_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8407ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Silhouette: 0.497\n",
      "LDA ARI: 0.146, NMI: 0.358, Purity: 0.495\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_clusters,          \n",
    "    doc_topic_prior=0.1,      \n",
    "    topic_word_prior=0.01,    \n",
    "    learning_decay=0.7,      \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "doc_topic_dist = lda.fit_transform(X)\n",
    "lda_labels = doc_topic_dist.argmax(axis=1)\n",
    "\n",
    "sil_lda = silhouette_score(doc_topic_dist, lda_labels)\n",
    "print(f\"LDA Silhouette: {sil_lda:.3f}\")\n",
    "\n",
    "if 'category' in df.columns:\n",
    "    ari_lda = adjusted_rand_score(df['category'], lda_labels)\n",
    "    nmi_lda = normalized_mutual_info_score(df['category'], lda_labels)\n",
    "    purity_lda = cluster_purity(df['category'].values, lda_labels)\n",
    "    print(f\"LDA ARI: {ari_lda:.3f}, NMI: {nmi_lda:.3f}, Purity: {purity_lda:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering Silhouette: 0.014\n",
      "Hierarchical ARI: 0.479, NMI: 0.594, Purity: 0.744\n"
     ]
    }
   ],
   "source": [
    "agglo = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "agglo_labels = agglo.fit_predict(X.toarray())\n",
    "sil_agglo = silhouette_score(X, agglo_labels)\n",
    "print(f\"Hierarchical Clustering Silhouette: {sil_agglo:.3f}\")\n",
    "\n",
    "if 'category' in df.columns:\n",
    "    ari_agglo = adjusted_rand_score(df['category'], agglo_labels)\n",
    "    nmi_agglo = normalized_mutual_info_score(df['category'], agglo_labels)\n",
    "    purity_agglo = cluster_purity(df['category'].values, agglo_labels)\n",
    "    print(f\"Hierarchical ARI: {ari_agglo:.3f}, NMI: {nmi_agglo:.3f}, Purity: {purity_agglo:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bc6bce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Silhouette: 0.020\n",
      "K-Means ARI: 0.791, NMI: 0.780, Purity: 0.911\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "sil_kmeans = silhouette_score(X, kmeans_labels)\n",
    "print(f\"K-Means Silhouette: {sil_kmeans:.3f}\")\n",
    "\n",
    "if 'category' in df.columns:\n",
    "    ari_kmeans = adjusted_rand_score(df['category'], kmeans_labels)\n",
    "    nmi_kmeans = normalized_mutual_info_score(df['category'], kmeans_labels)\n",
    "    purity_kmeans = cluster_purity(df['category'].values, kmeans_labels)\n",
    "    print(f\"K-Means ARI: {ari_kmeans:.3f}, NMI: {nmi_kmeans:.3f}, Purity: {purity_kmeans:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdac9c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-слова по кластерам K-Means с вероятной категорией:\n",
      "Cluster 0: game, player, england, club, match, win, team, champion, cup, world  ➔  sport\n",
      "Cluster 1: phone, people, technology, user, service, music, computer, software, network, site  ➔  tech\n",
      "Cluster 2: mr, election, party, labour, blair, tory, government, minister, tax, lord  ➔  politics\n",
      "Cluster 3: film, award, star, band, actor, album, music, year, festival, chart  ➔  entertainment\n",
      "Cluster 4: company, year, market, bank, growth, sale, economy, price, mr, share  ➔  business\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "n_top_words = 10\n",
    "\n",
    "print(\"Топ-слова по кластерам K-Means с вероятной категорией:\")\n",
    "for cluster in range(n_clusters):\n",
    "    mean_tfidf = X[kmeans_labels == cluster].mean(axis=0).A1\n",
    "    top_indices = np.argsort(mean_tfidf)[::-1][:n_top_words]\n",
    "    top_words = [feature_names[i] for i in top_indices]\n",
    "\n",
    "    cluster_cats = df.loc[kmeans_labels == cluster, 'category']\n",
    "    if len(cluster_cats) > 0:\n",
    "        majority_cat = cluster_cats.mode()[0]\n",
    "    else:\n",
    "        majority_cat = \"None\"\n",
    "    print(f\"Cluster {cluster}: {', '.join(top_words)}  ➔  {majority_cat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99291a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
