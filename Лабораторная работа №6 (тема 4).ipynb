{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36cc6015",
   "metadata": {},
   "source": [
    "Лабораторная работа №4: Автоматическое распознавание эмоциональной окраски речи\n",
    "\n",
    "Цель: Анализировать эмоциональную окраску речи с помощью методов NLP и глубоких нейронных сетей.\n",
    "Задания:\n",
    "- Собрать данные из социальных медиа (например, Twitter или VKontakte) и разметить их вручную по категориям эмоций (радость, грусть, гнев и др.).Метрика оценки: Точность классификации, Recall, Precision, F1-score.\n",
    "- Применить предобученную модель (RoBERTa, XLNet) для анализа эмоциональной окраски текста.Модели сравнения: SVM, Naive Bayes, KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "478a64f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset, DatasetDict \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from peft import (LoraConfig, \n",
    "                  prepare_model_for_kbit_training, \n",
    "                  get_peft_model,\n",
    "                  PeftModelForSequenceClassification,\n",
    "                  PeftConfig)\n",
    "\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForCausalLM,\n",
    "    Gemma3ForCausalLM)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import evaluate\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "graphic_card = '0'\n",
    "gpu_device = 'cuda:0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = graphic_card\n",
    "os.environ['CUDA_DEVICE_ORDER']= 'PCI_BUS_ID'\n",
    "device = torch.device(f'cuda:{graphic_card}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.cuda.set_device(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4990feed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_parquet_dataset(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    return Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "train_path = 'data/train-00000-of-00001.parquet'\n",
    "test_path = 'data/test-00000-of-00001.parquet'\n",
    "\n",
    "train_ds = load_parquet_dataset(train_path)\n",
    "test_ds = load_parquet_dataset(test_path)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'test': test_ds,\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87778acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_str'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_str'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_MAP = {\n",
    "    0: 'sadness',\n",
    "    1: 'joy',\n",
    "    2: 'love',\n",
    "    3: 'anger',\n",
    "    4: 'fear',\n",
    "    5: 'surprise',\n",
    "}\n",
    "\n",
    "def load_parquet_dataset(path):\n",
    "    df = pd.read_parquet(path)\n",
    "    df['label_str'] = df['label'].map(LABEL_MAP)\n",
    "    return Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "train_path = 'data/train-00000-of-00001.parquet'\n",
    "test_path = 'data/test-00000-of-00001.parquet'\n",
    "\n",
    "train_ds = load_parquet_dataset(train_path)\n",
    "test_ds = load_parquet_dataset(test_path)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'test': test_ds,\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f5913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_str\n",
       "0                            i didnt feel humiliated      0   sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0   sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3     anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2      love\n",
       "4                               i am feeling grouchy      3     anger"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcb04633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4de28a5c184471b27a0b77e32aef91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519eba9ca174469892963c28ebf4fc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2id = {\n",
    "    'sadness': 0,\n",
    "    'joy': 1,\n",
    "    'love': 2,\n",
    "    'anger': 3,\n",
    "    'fear': 4,\n",
    "    'surprise': 5,\n",
    "}\n",
    "id2class = {v: k for k, v in class2id.items()}\n",
    "\n",
    "hugging_face_model_id = 'google/gemma-3-4b-it'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    hugging_face_model_id,\n",
    "    padding_side='right',\n",
    "    add_bos_token=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    prompt = 'Determine the emotional tonality of the comment: '\n",
    "    texts = [prompt + t for t in examples['text']]\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64\n",
    "    )\n",
    "    enc['labels'] = examples['label']\n",
    "    return enc\n",
    "\n",
    "\n",
    "dataset_tokenized = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=['text', 'label', 'label_str']\n",
    ")\n",
    "\n",
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02830a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs   : [2, 102752, 506, 13690, 7998, 2027, 529, 506, 5739, 236787, 858, 59568, 2597, 179753, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label : 0  -->  sadness\n",
      "\n",
      "Tokens: <bos>Determine the emotional tonality of the comment: i didnt feel humiliated<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "sample_index = 0 \n",
    "\n",
    "sample_input_ids = dataset_tokenized['train']['input_ids'][sample_index]\n",
    "sample_label = dataset_tokenized['train']['labels'][sample_index]\n",
    "\n",
    "print(f'IDs   : {sample_input_ids}')\n",
    "print(f'Label : {sample_label}  -->  {id2class[sample_label]}\\n')\n",
    "print(f'Tokens: {tokenizer.decode(sample_input_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b70be188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 64]\n",
      "[64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "sample_batch_ids = dataset_tokenized['train']['input_ids'][0:3]\n",
    "sample_batch_ids_collator = data_collator(dataset_tokenized['train'][:3])['input_ids'][0:3]\n",
    "print([len(x) for x in sample_batch_ids ])\n",
    "print([len(x) for x in sample_batch_ids_collator ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d75417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1098b3f5924c76b2f968a251c6e087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "\n",
    "model = Gemma3ForCausalLM.from_pretrained(hugging_face_model_id, \n",
    "                                          torch_dtype=torch.bfloat16, \n",
    "                                          device_map=gpu_device,\n",
    "                                          attn_implementation='eager',\n",
    "                                          quantization_config=bnb_config  )\n",
    "\n",
    "model.lm_head = torch.nn.Linear(model.config.hidden_size, len(class2id.keys()), bias=False, device=gpu_device)\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec5c6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit \n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "        if 'lm_head' in lora_module_names: \n",
    "            lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "modules = ['gate_proj', 'down_proj', 'v_proj', 'k_proj', 'q_proj', 'o_proj', 'up_proj']\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    task_type='SEQ_CLS')\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81734bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemma3ForSequenceClassification(PeftModelForSequenceClassification):\n",
    "    def __init__(self, peft_config: PeftConfig, model: AutoModelForCausalLM, adapter_name='default'):\n",
    "        super().__init__(model, peft_config, adapter_name)\n",
    "        self.num_labels = model.config.num_labels\n",
    "        self.problem_type = 'multi_label_classification'\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "        **kwargs):\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.return_dict\n",
    "\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            **kwargs)\n",
    "\n",
    "        logits = outputs.logits\n",
    "\n",
    "        sequence_lengths = torch.sum(attention_mask, dim=1)\n",
    "        last_token_indices = sequence_lengths - 1\n",
    "        batch_size = logits.shape[0]\n",
    "       \n",
    "        logits = logits[torch.arange(batch_size, device=logits.device), last_token_indices, :]\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.problem_type == 'regression':\n",
    "                loss_fct = torch.nn.MSELoss()\n",
    "                loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "            else:\n",
    "                loss_fct = torch.nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03c76a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop('labels').to(model.device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "clf_metrics = evaluate.combine(['accuracy', 'f1', 'precision', 'recall'])\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "    labels_binarized = label_binarize(labels, classes=[0,1,2,3,4,5])\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1).numpy()\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(labels_binarized, probs, average='macro', multi_class='ovr')\n",
    "    except ValueError:\n",
    "        auc = float('nan') \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1_macro': f1_score(labels, preds, average='macro'),\n",
    "        'precision_macro': precision_score(labels, preds, average='macro'),\n",
    "        'recall_macro': recall_score(labels, preds, average='macro'),\n",
    "        'roc_auc_ovr': auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bac99912",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStoppingCallback(early_stopping_patience=3, \n",
    "                                   early_stopping_threshold=0.001) \n",
    "checkpoints_dir = 'results/gemma_emotions_classification' \n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "384ff88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    gradient_checkpointing=False,  \n",
    "    gradient_checkpointing_kwargs={'use_reentrant': False},\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    dataloader_num_workers=4,\n",
    "    output_dir= checkpoints_dir ,  \n",
    "    learning_rate=5e-5,  \n",
    "    per_device_train_batch_size=32,  \n",
    "    per_device_eval_batch_size=32,  \n",
    "    num_train_epochs=10,  \n",
    "    weight_decay=0.01,  \n",
    "    eval_strategy='steps', \n",
    "    eval_steps=100,     \n",
    "    save_strategy='steps',\n",
    "    save_steps=100,  \n",
    "    report_to='none',\n",
    "    load_best_model_at_end=True,  \n",
    "    push_to_hub=False,  \n",
    "    bf16=True,\n",
    "    warmup_ratio=0.05, \n",
    "    metric_for_best_model='eval_f1_macro',\n",
    "    greater_is_better=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c7bcb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `Gemma3ForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 800/5000 25:08 < 2:12:20, 0.53 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Roc Auc Ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.744000</td>\n",
       "      <td>1.487775</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.181611</td>\n",
       "      <td>0.187760</td>\n",
       "      <td>0.227137</td>\n",
       "      <td>0.639179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.094700</td>\n",
       "      <td>0.664278</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.696831</td>\n",
       "      <td>0.746317</td>\n",
       "      <td>0.695992</td>\n",
       "      <td>0.939403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.475400</td>\n",
       "      <td>0.381475</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.793263</td>\n",
       "      <td>0.848513</td>\n",
       "      <td>0.760413</td>\n",
       "      <td>0.983574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.280500</td>\n",
       "      <td>0.229384</td>\n",
       "      <td>0.924500</td>\n",
       "      <td>0.881519</td>\n",
       "      <td>0.896017</td>\n",
       "      <td>0.872764</td>\n",
       "      <td>0.992274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.195701</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.888316</td>\n",
       "      <td>0.884768</td>\n",
       "      <td>0.898797</td>\n",
       "      <td>0.995196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>0.170509</td>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.885694</td>\n",
       "      <td>0.886946</td>\n",
       "      <td>0.885009</td>\n",
       "      <td>0.996383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.169741</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.880569</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.866293</td>\n",
       "      <td>0.996406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.164837</td>\n",
       "      <td>0.930500</td>\n",
       "      <td>0.875048</td>\n",
       "      <td>0.909236</td>\n",
       "      <td>0.852725</td>\n",
       "      <td>0.996519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.19570104777812958,\n",
       " 'eval_accuracy': 0.926,\n",
       " 'eval_f1_macro': 0.8883164035049403,\n",
       " 'eval_precision_macro': 0.884768331457693,\n",
       " 'eval_recall_macro': 0.8987973603412537,\n",
       " 'eval_roc_auc_ovr': 0.995195725986641,\n",
       " 'eval_runtime': 33.8311,\n",
       " 'eval_samples_per_second': 59.117,\n",
       " 'eval_steps_per_second': 1.862,\n",
       " 'epoch': 1.6}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config = PeftConfig(peft_type='LORA', task_type='SEQ_CLS', inference_mode=False)\n",
    "for key, value in lora_config.__dict__.items():\n",
    "    setattr(peft_config, key, value)\n",
    "\n",
    "wrapped_model = Gemma3ForSequenceClassification(peft_config, model)\n",
    "wrapped_model.num_labels = len(class2id.keys())\n",
    "wrapped_model.config.id2label = id2class\n",
    "wrapped_model.config.label2id = class2id\n",
    "wrapped_model.config.problem_type = 'single_label_classification'\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=wrapped_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_tokenized['train'],\n",
    "    eval_dataset=dataset_tokenized['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop],\n",
    ")\n",
    "\n",
    "trainer.label_names = ['labels']\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: joy (id=1)\n",
      "All probs: {'sadness': 0.04197107255458832, 'joy': 0.8283224701881409, 'love': 0.0260604340583086, 'anger': 0.06693872064352036, 'fear': 0.026835216209292412, 'surprise': 0.009872124530375004}\n"
     ]
    }
   ],
   "source": [
    "wrapped_model.eval().to(device)\n",
    "\n",
    "def predict_emotion(text: str):\n",
    "    prompt = 'Determine the emotional tonality of the comment: '\n",
    "    enc = tokenizer(\n",
    "        prompt + text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = wrapped_model(**enc)\n",
    "        logits = outputs.logits       \n",
    "        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "        pred_id = int(np.argmax(probs))\n",
    "    \n",
    "    return {\n",
    "        'label_id': pred_id,\n",
    "        'label_str': id2class[pred_id],\n",
    "        'probabilities': { id2class[i]: float(probs[i]) for i in range(len(probs)) }\n",
    "    }\n",
    "\n",
    "res = predict_emotion(\"I can't wait for my vacation next week!\")\n",
    "print(f'Predicted: {res['label_str']} (id={res['label_id']})')\n",
    "print('All probs:', res['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660a5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== SVM (linear kernel) ===\n",
      "accuracy       : 0.8895\n",
      "precision_macro: 0.8552\n",
      "recall_macro   : 0.8118\n",
      "f1_macro       : 0.8302\n",
      "roc_auc_ovr    : 0.9879\n",
      "\n",
      "=== MultinomialNB ===\n",
      "accuracy       : 0.7145\n",
      "precision_macro: 0.7039\n",
      "recall_macro   : 0.4634\n",
      "f1_macro       : 0.4780\n",
      "roc_auc_ovr    : 0.9519\n",
      "\n",
      "=== KNN (k=5) ===\n",
      "accuracy       : 0.7255\n",
      "precision_macro: 0.7345\n",
      "recall_macro   : 0.6183\n",
      "f1_macro       : 0.6589\n",
      "roc_auc_ovr    : 0.8937\n"
     ]
    }
   ],
   "source": [
    "train_texts = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test = vectorizer.transform(test_texts)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "n_classes = len(set(y_train))\n",
    "y_test_binarized = label_binarize(y_test, classes=list(range(n_classes)))\n",
    "\n",
    "models = {\n",
    "    'SVM (linear kernel)': SVC(kernel='linear', probability=True, random_state=42),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'precision_macro': precision_score(y_test, preds, average='macro'),\n",
    "        'recall_macro': recall_score(y_test, preds, average='macro'),\n",
    "        'f1_macro': f1_score(y_test, preds, average='macro'),\n",
    "        'roc_auc_ovr': roc_auc_score(y_test_binarized, probs,\n",
    "                                          average='macro',\n",
    "                                          multi_class='ovr'),\n",
    "    }\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    print(f'\\n=== {name} ===')\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f'{metric_name:15s}: {value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f092d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
